## Deep Learning Foundations for Image Analysis

![GitHub top language](https://img.shields.io/github/languages/top/shihabmuhtasim/Neural-Networks-and-Deep-Learning--Coursera?color=f5f5dc) 
![GitHub language count](https://img.shields.io/github/languages/count/shihabmuhtasim/Neural-Networks-and-Deep-Learning--Coursera?color=f5f5dc) 
![GitHub last commit](https://img.shields.io/github/last-commit/shihabmuhtasim/Neural-Networks-and-Deep-Learning--Coursera?color=f5f5dc) 
![GitHub repo file count](https://img.shields.io/github/directory-file-count/shihabmuhtasim/Neural-Networks-and-Deep-Learning--Coursera?color=f5f5dc)
![GitHub repo size](https://img.shields.io/github/repo-size/shihabmuhtasim/Neural-Networks-and-Deep-Learning--Coursera?color=f5f5dc)
![GitHub watchers](https://img.shields.io/github/watchers/shihabmuhtasim/Neural-Networks-and-Deep-Learning--Coursera?style=social)



This repository showcases the building blocks of a comprehensive deep learning pipeline for image analysis. These projects provide a step-by-step foundation in understanding and implementing core concepts of neural networks, with applications in image classification and beyond.

## Projects: Building Blocks

### 1. Building a Deep Neural Network: Step by Step
The first building block focuses on implementing the core components of a deep neural network. This project introduces:
- Parameter initialization for multi-layer neural networks.
- Forward and backward propagation.
- Parameter updates using gradient descent.

### 2. Deep Neural Network for Image Classification
This project demonstrates the application of deep learning for image classification, specifically a binary task (cat vs non-cat). It includes:
- Training a 2-layer and an L-layer neural network.
- Evaluating performance using accuracy metrics.

### 3. Logistic Regression as a Neural Network
This introductory block lays the groundwork by implementing logistic regression as a simple neural network, providing insights into the connection between logistic regression and deep learning.

### 4. Regularization in Deep Learning
Regularization techniques like L2 regularization and dropout are implemented in this project to enhance model generalization and prevent overfitting.

### 5. Optimization Algorithms for Neural Networks
This final block explores optimization methods such as:
- Mini-batch gradient descent.
- Momentum.
- RMSprop and Adam optimizers.
These techniques ensure efficient and accurate training of neural networks.

## Features
- Step-by-step implementation of deep learning concepts.
- Python libraries like `numpy`, `matplotlib`, and `h5py` are used.
- Focus on understanding imaging-related neural network applications.



![image](https://github.com/shihabmuhtasim/Neural-Networks-and-Deep-Learning--Coursera/assets/92597456/68098663-8166-4715-86fd-c368e99f9c03)
